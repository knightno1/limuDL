{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e91c3771",
      "metadata": {
        "id": "e91c3771"
      },
      "source": [
        "The following additional libraries are needed to run this\n",
        "notebook. Note that running on Colab is experimental, please report a Github\n",
        "issue if you have any problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d6e07e84",
      "metadata": {
        "id": "d6e07e84",
        "outputId": "45d2ccaa-c3ce-4ac8-b402-ec4bc0f4df57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/d2l-ai/d2l-zh@release\n",
            "  Cloning https://github.com/d2l-ai/d2l-zh (to revision release) to /tmp/pip-req-build-xf0zulo0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/d2l-ai/d2l-zh /tmp/pip-req-build-xf0zulo0\n",
            "  Running command git checkout -b release --track origin/release\n",
            "  Switched to a new branch 'release'\n",
            "  Branch 'release' set up to track remote branch 'release' from 'origin'.\n",
            "  Resolved https://github.com/d2l-ai/d2l-zh to commit 843d3d41dca48d8df65f4b324dd171d8bfe9c067\n",
            "  Running command git submodule update --init --recursive -q\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jupyter==1.0.0 (from d2l==2.0.0)\n",
            "  Downloading jupyter-1.0.0-py2.py3-none-any.whl.metadata (995 bytes)\n",
            "INFO: pip is looking at multiple versions of d2l to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Ignored the following versions that require a different python version: 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement numpy==1.21.5 (from d2l) (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0, 1.11.1, 1.11.2, 1.11.3, 1.12.0, 1.12.1, 1.13.0, 1.13.1, 1.13.3, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0, 1.16.1, 1.16.2, 1.16.3, 1.16.4, 1.16.5, 1.16.6, 1.17.0, 1.17.1, 1.17.2, 1.17.3, 1.17.4, 1.17.5, 1.18.0, 1.18.1, 1.18.2, 1.18.3, 1.18.4, 1.18.5, 1.19.0, 1.19.1, 1.19.2, 1.19.3, 1.19.4, 1.19.5, 1.20.0, 1.20.1, 1.20.2, 1.20.3, 1.21.0, 1.21.1, 1.22.0, 1.22.1, 1.22.2, 1.22.3, 1.22.4, 1.23.0, 1.23.1, 1.23.2, 1.23.3, 1.23.4, 1.23.5, 1.24.0, 1.24.1, 1.24.2, 1.24.3, 1.24.4, 1.25.0, 1.25.1, 1.25.2, 1.26.0, 1.26.1, 1.26.2, 1.26.3, 1.26.4, 2.0.0, 2.0.1, 2.0.2, 2.1.0rc1, 2.1.0, 2.1.1, 2.1.2, 2.1.3, 2.2.0rc1, 2.2.0, 2.2.1, 2.2.2, 2.2.3, 2.2.4, 2.2.5)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for numpy==1.21.5\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting mxnet-cu101==1.7.0\n",
            "  Downloading mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting numpy<2.0.0,>1.16.0 (from mxnet-cu101==1.7.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.11/dist-packages (from mxnet-cu101==1.7.0) (2.32.3)\n",
            "Collecting graphviz<0.9.0,>=0.8.1 (from mxnet-cu101==1.7.0)\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.20.0->mxnet-cu101==1.7.0) (2025.1.31)\n",
            "Downloading mxnet_cu101-1.7.0-py2.py3-none-manylinux2014_x86_64.whl (846.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m846.0/846.0 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, graphviz, mxnet-cu101\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.3\n",
            "    Uninstalling graphviz-0.20.3:\n",
            "      Successfully uninstalled graphviz-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed graphviz-0.8.4 mxnet-cu101-1.7.0 numpy-1.26.4\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/d2l-ai/d2l-zh@release  # installing d2l\n",
        "!pip install -U mxnet-cu101==1.7.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77867128",
      "metadata": {
        "origin_pos": 0,
        "id": "77867128"
      },
      "source": [
        "# 线性回归的简洁实现\n",
        ":label:`sec_linear_concise`\n",
        "\n",
        "在过去的几年里，出于对深度学习强烈的兴趣，\n",
        "许多公司、学者和业余爱好者开发了各种成熟的开源框架。\n",
        "这些框架可以自动化基于梯度的学习算法中重复性的工作。\n",
        "在 :numref:`sec_linear_scratch`中，我们只运用了：\n",
        "（1）通过张量来进行数据存储和线性代数；\n",
        "（2）通过自动微分来计算梯度。\n",
        "实际上，由于数据迭代器、损失函数、优化器和神经网络层很常用，\n",
        "现代深度学习库也为我们实现了这些组件。\n",
        "\n",
        "本节将介绍如何(**通过使用深度学习框架来简洁地实现**)\n",
        " :numref:`sec_linear_scratch`中的(**线性回归模型**)。\n",
        "\n",
        "## 生成数据集\n",
        "\n",
        "与 :numref:`sec_linear_scratch`中类似，我们首先[**生成数据集**]。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b630e311",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:02:57.664335Z",
          "iopub.status.busy": "2023-08-18T07:02:57.663401Z",
          "iopub.status.idle": "2023-08-18T07:03:00.456668Z",
          "shell.execute_reply": "2023-08-18T07:03:00.455522Z"
        },
        "origin_pos": 1,
        "tab": [
          "mxnet"
        ],
        "id": "b630e311",
        "outputId": "af8068f8-837a-4bc8-e505-22fde0808698",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "libcudart.so.10.1: cannot open shared object file: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-f4edc2f02abd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgluon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnpx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmxnet\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_np\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mxnet/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\"\"\"MXNet: a concise, fast and flexible framework for deep learning.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcpu_pinned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMXNetError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mxnet/context.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassproperty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_metaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_MXClassPropertyMetaClass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_LIB\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mxnet/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[0;31m# library instance of mxnet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;31m# type definitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/mxnet/base.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    340\u001b[0m     \u001b[0;34m\"\"\"Load library by searching possible path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlib_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibinfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_lib_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRTLD_LOCAL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m     \u001b[0;31m# DMatrix functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMXGetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: libcudart.so.10.1: cannot open shared object file: No such file or directory"
          ]
        }
      ],
      "source": [
        "from mxnet import autograd, gluon, np, npx\n",
        "from d2l import mxnet as d2l\n",
        "\n",
        "npx.set_np()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "510bcc83",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.461526Z",
          "iopub.status.busy": "2023-08-18T07:03:00.460773Z",
          "iopub.status.idle": "2023-08-18T07:03:00.470162Z",
          "shell.execute_reply": "2023-08-18T07:03:00.469150Z"
        },
        "origin_pos": 5,
        "tab": [
          "mxnet"
        ],
        "id": "510bcc83",
        "outputId": "42804389-c741-40f1-c333-3ab242a0cc01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:03:00] ../src/storage/storage.cc:196: Using Pooled (Naive) StorageManager for CPU\n"
          ]
        }
      ],
      "source": [
        "true_w = np.array([2, -3.4])\n",
        "true_b = 4.2\n",
        "features, labels = d2l.synthetic_data(true_w, true_b, 1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35eabd5a",
      "metadata": {
        "origin_pos": 6,
        "id": "35eabd5a"
      },
      "source": [
        "## 读取数据集\n",
        "\n",
        "我们可以[**调用框架中现有的API来读取数据**]。\n",
        "我们将`features`和`labels`作为API的参数传递，并通过数据迭代器指定`batch_size`。\n",
        "此外，布尔值`is_train`表示是否希望数据迭代器对象在每个迭代周期内打乱数据。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e88d24f0",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.474112Z",
          "iopub.status.busy": "2023-08-18T07:03:00.473818Z",
          "iopub.status.idle": "2023-08-18T07:03:00.478546Z",
          "shell.execute_reply": "2023-08-18T07:03:00.477700Z"
        },
        "origin_pos": 7,
        "tab": [
          "mxnet"
        ],
        "id": "e88d24f0"
      },
      "outputs": [],
      "source": [
        "def load_array(data_arrays, batch_size, is_train=True):  #@save\n",
        "    \"\"\"构造一个Gluon数据迭代器\"\"\"\n",
        "    dataset = gluon.data.ArrayDataset(*data_arrays)\n",
        "    return gluon.data.DataLoader(dataset, batch_size, shuffle=is_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f5a0721",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.482289Z",
          "iopub.status.busy": "2023-08-18T07:03:00.481617Z",
          "iopub.status.idle": "2023-08-18T07:03:00.542786Z",
          "shell.execute_reply": "2023-08-18T07:03:00.541675Z"
        },
        "origin_pos": 11,
        "tab": [
          "mxnet"
        ],
        "id": "1f5a0721"
      },
      "outputs": [],
      "source": [
        "batch_size = 10\n",
        "data_iter = load_array((features, labels), batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b1b9532",
      "metadata": {
        "origin_pos": 12,
        "id": "2b1b9532"
      },
      "source": [
        "使用`data_iter`的方式与我们在 :numref:`sec_linear_scratch`中使用`data_iter`函数的方式相同。为了验证是否正常工作，让我们读取并打印第一个小批量样本。\n",
        "与 :numref:`sec_linear_scratch`不同，这里我们使用`iter`构造Python迭代器，并使用`next`从迭代器中获取第一项。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bbf9442",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.546649Z",
          "iopub.status.busy": "2023-08-18T07:03:00.546345Z",
          "iopub.status.idle": "2023-08-18T07:03:00.562820Z",
          "shell.execute_reply": "2023-08-18T07:03:00.561929Z"
        },
        "origin_pos": 13,
        "tab": [
          "mxnet"
        ],
        "id": "9bbf9442",
        "outputId": "6e7b7099-b85f-4c58-a1a3-e87174752cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([[ 0.6631022 , -0.16627775],\n",
              "        [ 1.4011933 , -0.19310263],\n",
              "        [-0.9567186 , -1.6827176 ],\n",
              "        [-0.7114856 , -2.0320427 ],\n",
              "        [ 0.8230793 , -0.26465464],\n",
              "        [-1.0424827 ,  0.35005474],\n",
              "        [-0.594405  ,  0.7975923 ],\n",
              "        [ 1.1555725 , -0.13389243],\n",
              "        [-0.1386715 ,  0.7079162 ],\n",
              "        [ 1.0653706 , -0.02712403]]),\n",
              " array([[6.0939207 ],\n",
              "        [7.659188  ],\n",
              "        [8.01163   ],\n",
              "        [9.69425   ],\n",
              "        [6.749446  ],\n",
              "        [0.91951895],\n",
              "        [0.30207413],\n",
              "        [6.9719377 ],\n",
              "        [1.5070254 ],\n",
              "        [6.423725  ]])]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "next(iter(data_iter))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb0d6085",
      "metadata": {
        "origin_pos": 14,
        "id": "cb0d6085"
      },
      "source": [
        "## 定义模型\n",
        "\n",
        "当我们在 :numref:`sec_linear_scratch`中实现线性回归时，\n",
        "我们明确定义了模型参数变量，并编写了计算的代码，这样通过基本的线性代数运算得到输出。\n",
        "但是，如果模型变得更加复杂，且当我们几乎每天都需要实现模型时，自然会想简化这个过程。\n",
        "这种情况类似于为自己的博客从零开始编写网页。\n",
        "做一两次是有益的，但如果每个新博客就需要工程师花一个月的时间重新开始编写网页，那并不高效。\n",
        "\n",
        "对于标准深度学习模型，我们可以[**使用框架的预定义好的层**]。这使我们只需关注使用哪些层来构造模型，而不必关注层的实现细节。\n",
        "我们首先定义一个模型变量`net`，它是一个`Sequential`类的实例。\n",
        "`Sequential`类将多个层串联在一起。\n",
        "当给定输入数据时，`Sequential`实例将数据传入到第一层，\n",
        "然后将第一层的输出作为第二层的输入，以此类推。\n",
        "在下面的例子中，我们的模型只包含一个层，因此实际上不需要`Sequential`。\n",
        "但是由于以后几乎所有的模型都是多层的，在这里使用`Sequential`会让你熟悉“标准的流水线”。\n",
        "\n",
        "回顾 :numref:`fig_single_neuron`中的单层网络架构，\n",
        "这一单层被称为*全连接层*（fully-connected layer），\n",
        "因为它的每一个输入都通过矩阵-向量乘法得到它的每个输出。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "76a2c866",
      "metadata": {
        "origin_pos": 15,
        "tab": [
          "mxnet"
        ],
        "id": "76a2c866"
      },
      "source": [
        "在Gluon中，全连接层在`Dense`类中定义。\n",
        "由于我们只想得到一个标量输出，所以我们将该数字设置为1。\n",
        "\n",
        "值得注意的是，为了方便使用，Gluon并不要求我们为每个层指定输入的形状。\n",
        "所以在这里，我们不需要告诉Gluon有多少输入进入这一层。\n",
        "当我们第一次尝试通过我们的模型传递数据时，例如，当后面执行`net(X)`时，\n",
        "Gluon会自动推断每个层输入的形状。\n",
        "本节稍后将详细介绍这种工作机制。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27096cb6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.566766Z",
          "iopub.status.busy": "2023-08-18T07:03:00.566207Z",
          "iopub.status.idle": "2023-08-18T07:03:00.570806Z",
          "shell.execute_reply": "2023-08-18T07:03:00.569726Z"
        },
        "origin_pos": 19,
        "tab": [
          "mxnet"
        ],
        "id": "27096cb6"
      },
      "outputs": [],
      "source": [
        "# nn是神经网络的缩写\n",
        "from mxnet.gluon import nn\n",
        "\n",
        "net = nn.Sequential()\n",
        "net.add(nn.Dense(1))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84f31e5b",
      "metadata": {
        "origin_pos": 23,
        "id": "84f31e5b"
      },
      "source": [
        "## (**初始化模型参数**)\n",
        "\n",
        "在使用`net`之前，我们需要初始化模型参数。\n",
        "如在线性回归模型中的权重和偏置。\n",
        "深度学习框架通常有预定义的方法来初始化参数。\n",
        "在这里，我们指定每个权重参数应该从均值为0、标准差为0.01的正态分布中随机采样，\n",
        "偏置参数将初始化为零。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "60d13202",
      "metadata": {
        "origin_pos": 24,
        "tab": [
          "mxnet"
        ],
        "id": "60d13202"
      },
      "source": [
        "我们从MXNet导入`initializer`模块，这个模块提供了各种模型参数初始化方法。\n",
        "Gluon将`init`作为访问`initializer`包的快捷方式。\n",
        "我们可以通过调用`init.Normal(sigma=0.01)`来指定初始化权重的方法。\n",
        "默认情况下，偏置参数初始化为零。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65f8df57",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.574209Z",
          "iopub.status.busy": "2023-08-18T07:03:00.573941Z",
          "iopub.status.idle": "2023-08-18T07:03:00.579980Z",
          "shell.execute_reply": "2023-08-18T07:03:00.579146Z"
        },
        "origin_pos": 28,
        "tab": [
          "mxnet"
        ],
        "id": "65f8df57"
      },
      "outputs": [],
      "source": [
        "from mxnet import init\n",
        "\n",
        "net.initialize(init.Normal(sigma=0.01))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7576439d",
      "metadata": {
        "origin_pos": 32,
        "tab": [
          "mxnet"
        ],
        "id": "7576439d"
      },
      "source": [
        "上面的代码可能看起来很简单，但是这里有一个应该注意到的细节：\n",
        "我们正在为网络初始化参数，而Gluon还不知道输入将有多少维!\n",
        "网络的输入可能有2维，也可能有2000维。\n",
        "Gluon让我们避免了这个问题，在后端执行时，初始化实际上是*推迟*（deferred）执行的，\n",
        "只有在我们第一次尝试通过网络传递数据时才会进行真正的初始化。\n",
        "请注意，因为参数还没有初始化，所以我们不能访问或操作它们。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f2b777",
      "metadata": {
        "origin_pos": 35,
        "id": "a4f2b777"
      },
      "source": [
        "## 定义损失函数\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "860acf5b",
      "metadata": {
        "origin_pos": 36,
        "tab": [
          "mxnet"
        ],
        "id": "860acf5b"
      },
      "source": [
        "在Gluon中，`loss`模块定义了各种损失函数。\n",
        "在这个例子中，我们将使用Gluon中的均方误差（`L2Loss`）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360a85b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.583871Z",
          "iopub.status.busy": "2023-08-18T07:03:00.583159Z",
          "iopub.status.idle": "2023-08-18T07:03:00.587348Z",
          "shell.execute_reply": "2023-08-18T07:03:00.586395Z"
        },
        "origin_pos": 40,
        "tab": [
          "mxnet"
        ],
        "id": "360a85b9"
      },
      "outputs": [],
      "source": [
        "loss = gluon.loss.L2Loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35626462",
      "metadata": {
        "origin_pos": 44,
        "id": "35626462"
      },
      "source": [
        "## 定义优化算法\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f61e007e",
      "metadata": {
        "origin_pos": 45,
        "tab": [
          "mxnet"
        ],
        "id": "f61e007e"
      },
      "source": [
        "小批量随机梯度下降算法是一种优化神经网络的标准工具，\n",
        "Gluon通过`Trainer`类支持该算法的许多变种。\n",
        "当我们实例化`Trainer`时，我们要指定优化的参数\n",
        "（可通过`net.collect_params()`从我们的模型`net`中获得）、\n",
        "我们希望使用的优化算法（`sgd`）以及优化算法所需的超参数字典。\n",
        "小批量随机梯度下降只需要设置`learning_rate`值，这里设置为0.03。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f73cb281",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.591120Z",
          "iopub.status.busy": "2023-08-18T07:03:00.590416Z",
          "iopub.status.idle": "2023-08-18T07:03:00.595647Z",
          "shell.execute_reply": "2023-08-18T07:03:00.594338Z"
        },
        "origin_pos": 49,
        "tab": [
          "mxnet"
        ],
        "id": "f73cb281"
      },
      "outputs": [],
      "source": [
        "from mxnet import gluon\n",
        "\n",
        "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.03})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3d7d05d7",
      "metadata": {
        "origin_pos": 53,
        "id": "3d7d05d7"
      },
      "source": [
        "## 训练\n",
        "\n",
        "通过深度学习框架的高级API来实现我们的模型只需要相对较少的代码。\n",
        "我们不必单独分配参数、不必定义我们的损失函数，也不必手动实现小批量随机梯度下降。\n",
        "当我们需要更复杂的模型时，高级API的优势将大大增加。\n",
        "当我们有了所有的基本组件，[**训练过程代码与我们从零开始实现时所做的非常相似**]。\n",
        "\n",
        "回顾一下：在每个迭代周期里，我们将完整遍历一次数据集（`train_data`），\n",
        "不停地从中获取一个小批量的输入和相应的标签。\n",
        "对于每一个小批量，我们会进行以下步骤:\n",
        "\n",
        "* 通过调用`net(X)`生成预测并计算损失`l`（前向传播）。\n",
        "* 通过进行反向传播来计算梯度。\n",
        "* 通过调用优化器来更新模型参数。\n",
        "\n",
        "为了更好的衡量训练效果，我们计算每个迭代周期后的损失，并打印它来监控训练过程。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c73c4ae",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:00.599666Z",
          "iopub.status.busy": "2023-08-18T07:03:00.599056Z",
          "iopub.status.idle": "2023-08-18T07:03:01.870736Z",
          "shell.execute_reply": "2023-08-18T07:03:01.869562Z"
        },
        "origin_pos": 54,
        "tab": [
          "mxnet"
        ],
        "id": "0c73c4ae",
        "outputId": "ea9091c5-9495-48a4-eae5-821201b6726d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[07:03:00] ../src/base.cc:48: GPU context requested, but no GPUs found.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1, loss 0.024902\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2, loss 0.000086\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3, loss 0.000051\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 3\n",
        "for epoch in range(num_epochs):\n",
        "    for X, y in data_iter:\n",
        "        with autograd.record():\n",
        "            l = loss(net(X), y)\n",
        "        l.backward()\n",
        "        trainer.step(batch_size)\n",
        "    l = loss(net(features), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {l.mean().asnumpy():f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b00d8561",
      "metadata": {
        "origin_pos": 58,
        "id": "b00d8561"
      },
      "source": [
        "下面我们[**比较生成数据集的真实参数和通过有限数据训练获得的模型参数**]。\n",
        "要访问参数，我们首先从`net`访问所需的层，然后读取该层的权重和偏置。\n",
        "正如在从零开始实现中一样，我们估计得到的参数与生成数据的真实参数非常接近。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0582a84e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-08-18T07:03:01.875491Z",
          "iopub.status.busy": "2023-08-18T07:03:01.874800Z",
          "iopub.status.idle": "2023-08-18T07:03:01.882673Z",
          "shell.execute_reply": "2023-08-18T07:03:01.881588Z"
        },
        "origin_pos": 59,
        "tab": [
          "mxnet"
        ],
        "id": "0582a84e",
        "outputId": "57f720f4-5b93-4c5d-baad-c83601dc9d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w的估计误差： [0.00050712 0.0001173 ]\n",
            "b的估计误差： [0.00094557]\n"
          ]
        }
      ],
      "source": [
        "w = net[0].weight.data()\n",
        "print(f'w的估计误差： {true_w - w.reshape(true_w.shape)}')\n",
        "b = net[0].bias.data()\n",
        "print(f'b的估计误差： {true_b - b}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e953c00e",
      "metadata": {
        "origin_pos": 63,
        "id": "e953c00e"
      },
      "source": [
        "## 小结\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d4f92c0",
      "metadata": {
        "origin_pos": 64,
        "tab": [
          "mxnet"
        ],
        "id": "9d4f92c0"
      },
      "source": [
        "* 我们可以使用Gluon更简洁地实现模型。\n",
        "* 在Gluon中，`data`模块提供了数据处理工具，`nn`模块定义了大量的神经网络层，`loss`模块定义了许多常见的损失函数。\n",
        "* MXNet的`initializer`模块提供了各种模型参数初始化方法。\n",
        "* 维度和存储可以自动推断，但注意不要在初始化参数之前尝试访问参数。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22df3168",
      "metadata": {
        "origin_pos": 67,
        "id": "22df3168"
      },
      "source": [
        "## 练习\n",
        "\n",
        "1. 如果将小批量的总损失替换为小批量损失的平均值，需要如何更改学习率？\n",
        "1. 查看深度学习框架文档，它们提供了哪些损失函数和初始化方法？用Huber损失代替原损失，即\n",
        "    $$l(y,y') = \\begin{cases}|y-y'| -\\frac{\\sigma}{2} & \\text{ if } |y-y'| > \\sigma \\\\ \\frac{1}{2 \\sigma} (y-y')^2 & \\text{ 其它情况}\\end{cases}$$\n",
        "1. 如何访问线性回归的梯度？\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5642797e",
      "metadata": {
        "origin_pos": 68,
        "tab": [
          "mxnet"
        ],
        "id": "5642797e"
      },
      "source": [
        "[Discussions](https://discuss.d2l.ai/t/1782)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "required_libs": [],
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}